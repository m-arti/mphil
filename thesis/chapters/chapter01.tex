%************************************************
\begin{document}
\chapter{Overview}\label{ch:overview}
%************************************************
\vspace*{-\baselineskip}
\newthought{The impact of} news on daily affairs is arguably greater than it has ever been. Its importance today can hardly be overstated. Although its ubiquity and influx make news readily available, the news—despite being mostly useful—is increasingly becoming skewed away from truth, towards more sensational headlines, as competition for readership becomes more difficult.\sidenote{\citeauthoryear{Wang:2012}, \citeauthoryear{Kavanagh:2019}}

The news plays many roles. It informs the populace, inspires hope, and initiates conversation, to name but a few. However, it sometimes leans towards rhetoric rather than facts, so it is not always reliable. The news can also overwhelm with its dizzying speed and endless breadth of topics. It can be argued that it would be almost impossible to detach the news from everything else. The world may not be able to function without it. Consequently, news can be leveraged for virtuous, or vicious activities.

The fabrication and dissemination of falsehood have become politically and economically lucrative endeavours, as well as tools for social and ideological manoeuvre. Thus, the present times have been labelled as a \emph{post-truth} period. These endeavours have led to an intricately complex and constantly evolving phenomenon that is mainly characterised by \emph{disinformation} (false information which is created or shared with malicious intent) and \emph{misinformation} (also false, but shared with harmless intentions). The pair is commonly collectively referred to as \emph{fake news}.\sidenote{The uses and misuses of this term are discussed in more detail in \sectionref{sec:1-infodis}.}

\newthought{Several domains are} affected by misinformation, especially in situations that involve or affect many people, where uncertainty and tensions are high, and resolutions are not forthcoming. These domains include but are not limited to:\sidenote{\citeauthoryear{Allcott:2017}, \citeauthoryear{USDHS:2018}, \citeauthoryear{Waldman:2018}, \citeauthoryear{Wardle:2020}, \citeauthoryear{Chowdhury:2021}}

\begin{itemize}
    \item \underline{Politics}: misinformation has historically and globally played a consequential role in politics. A recent example of this is during the 2016 U.S. Presidential Elections.
    \item \underline{Healthcare}: during an epidemic such as the Ebola disease outbreak in 2014, or a pandemic such as COVID-19, misinformation also spreads, particularly through social media.
    \item \underline{Natural disasters}: examples include sharing falsified information (\emph{e.g.}, following the Fukushima Daiichi nuclear disaster in Japan, in 2011); inadequate (\emph{e.g.}, during the earthquake in Nepal, in 2015); or mis-contextualised (\emph{e.g.}, during an earthquake in Sicily, in 2014, whereby news of another one from 1908 was referenced).
\end{itemize}

Central to this thesis is a computational investigation into some of the characteristics of fake news text that differentiate it from truthful news. The texts analysed in this work are in short and long forms—tweets related to news events and full-length news articles, respectively. The datasets cover diverse domains, including politics, sports, and conflict.

To better understand misinformation, it is important to first understand what news is. The \acf{OED} \citeDateToBib{OED:news}{\citeyear{OED:news}} defines\sidenote{This is the most relevant definition in the context of this thesis.} \emph{news} as:

\begin{quote}
  \begin{Center}
  \emph{`The report or account of recent (esp. important or interesting) events or occurrences, brought or coming to one as new information; new occurrences as a subject of report or talk; tidings.'}
  \end{Center}
\end{quote}

It is a somewhat subjective matter which events may qualify as important or interesting. However, it can objectively be stated, that the alteration of new information can distort a news report to the extent of falsifying events, thereby rendering the news false. Certainly, even if all the information is true and verified, the reportage can confuse or mislead, for instance, by means of rhetoric. It is clear then, that faithfully narrating a vapid event in an engrossing manner, does not constitute fake news, but perhaps is the result of skill or passion. On the other hand, regardless of how interesting an event is, its misrepresentation may misinform or disinform the reader. Therefore, it is important to categorise the various ways in which—and degrees to which—information can be falsified. This is because by doing so, a typology for distinguishing the different types of misinformation can be created. Such a typology helps to identify the specific kind of problem being dealt with, and in finding the optimum mitigation against it. In this thesis, a typology called \emph{Information Disorder}, which captures the essence and full breadth of the mis- and disinformation landscape, is adopted. This is discussed in the next section (\sectionref{sec:1-infodis}).

\newthought{A plethora of} sources\sidequote{The news knows how to render its own mechanics almost invisible and therefore hard to question.}{Alain de Botton}{}{The News: A User’s Manual} now vie for the attention of readers—perhaps, more than ever before. As a result, editors and journalists may be incentivised to produce more sensational or emotionally charged pieces to invite, maintain or grow readership. This is not a critique of journalists, nor an assessment of their practices as measured against the principles and standards which apply to their field. Rather, it is simply an observation of a trend. In many fields, business and economic motives can clash with principles, and journalism is no exception. As discussed later in this chapter,\sidenote{See \sectionref{ssec:1-history} and \sectionref{ssec:1-efforts}.} besides sensationalism and bias, advertising is one of the ways through which misinformation seeps into news pieces.

The lure of misinformation on social media typically begins with the title of an article—often heightened by accompanying photographs. In the so-called \emph{attention economy}, attention is offered primacy because it is scant. With limited space, in adjacency with other publications, and within a publication itself, titles must therefore strive to be eye-catching. This is often done at the expense of high-quality information; at the same time, readers with limited attention tend to share tawdry information.\sidecite{Menczer:2020}

As for the main content of a piece, a compelling story is naturally more captivating than a list of factual statements. Facts tend to be either bland and predictable, and therefore boring—or strange and new, and therefore interesting. Most people possibly prefer the latter.

\section{Information Disorder}
\label{sec:1-infodis}

Mis- and disinformation are intertwined but essentially distinct phenomena. They form a part of the broader landscape of what's commonly, and often inaccurately, called `fake news'. People, especially on the internet, have become accustomed to referring to the entire landscape of false information as fake news. Although the term suffices to indicate various types of false information and even sophistry in biased articles, its unbridled use is problematic.\sidenote{A concise etymology of the term `fake news' is related in \sectionref{ssec:fake-news}, as well as examples of its misuse.}

The misinformation landscape as a whole is so complicated, that there is currently no firm consensus on terminology, nomenclature, and definitions amongst researchers of the subject. Nonetheless, due to the acceleration of research in the area, the different types of fake news are becoming more firmly grouped.

\sidequote{When it was reported that Hemingway's plane had been sighted, wrecked, in Africa, the New York Mirror ran a headline saying, "Hemingway Lost in Africa," the word "lost" being used to suggest he was dead. When it turned out he was alive, the Mirror left the headline to be taken literally.}{Donald Davidson}{}{What Metaphors Mean} \citeauthoryear{Wardle:2017} was among the first to propose a typology of fake news. It consisted of seven main categories, in increasing order of harmfulness: satire or parody, false connection, misleading content, false context, imposter content, manipulated content, and fabricated content. The groups were based on three criteria: the type of information created and shared, the motivation behind the creation of the content, and how it is disseminated. Though it received some pushback, Wardle assiduously defended the inclusion of satire as a category in a revised edition of her typology.\sidecite{Wardle:2020} Having acknowledged that satire (when intelligent) is a form of art, she explained that it is slyly used to veil canards and conspiracies, and thus divert the attention of fact-checkers. Moreover, should such a piece be later detected, its authors can simply claim that it was, after all, not intended to be taken seriously. \autoref{tab:matrix}\sidenote{Adapted from \citeauthoryear{Wardle:2020}.} summarises the types of mis- and disinformation and their motivations, according to \citeauthoryear{Wardle:2020}.

\begin{threeparttable}
\addlinespace
\begin{tabularx}{480pt}{>{\raggedright}p{2cm}>{\raggedright}p{5.5cm}cccccccc}
  \toprule
  \tableheadline{Type} & \tableheadline{Description} & {\rotatebox[origin=c]{90}{\tableheadline{Poor journalism}}} & {\rotatebox[origin=c]{90}{\tableheadline{To parody}}} & {\rotatebox[origin=c]{90}{\tableheadline{To provoke/`punk'}}} & {\rotatebox[origin=c]{90}{\tableheadline{Passion}}} & {\rotatebox[origin=c]{90}{\tableheadline{Partisanship}}} & {\rotatebox[origin=c]{90}{\tableheadline{Profit}}} & {\rotatebox[origin=c]{90}{\tableheadline{Political influence}}} & {\rotatebox[origin=c]{90}{\tableheadline{Propaganda}}} \\
  \midrule

  Satire/Parody & No intention to cause harm but has intention to fool & \checkmark & \checkmark & \spacechar & \spacechar & \spacechar & \spacechar & \spacechar & \spacechar \\
  \midrule

  False connection & When headlines, visuals or captions don't support the content & \checkmark & \spacechar & \spacechar & \spacechar & \spacechar & \checkmark & \spacechar & \spacechar \\
  \midrule

  Misleading content & Misleading use of information to frame an issue or individual & \checkmark & \spacechar & \spacechar & \spacechar & \checkmark & \spacechar & \checkmark & \checkmark \\
  \midrule

  False context & When genuine content is shared with false contextual information & \checkmark & \spacechar & \spacechar & \checkmark & \checkmark & \spacechar & \checkmark & \checkmark \\
  \midrule

  Imposter content & When genuine sources are impersonated & \spacechar & \checkmark & \checkmark & \spacechar & \spacechar & \checkmark & \spacechar & \checkmark \\
  \midrule

  Manipulated content & When genuine information or imagery is manipulated to deceive & \spacechar & \spacechar & \checkmark & \spacechar & \spacechar & \spacechar & \checkmark & \checkmark \\
  \midrule

  Fabricated content & New content that is 100\% false, made to deceive and do harm & \spacechar & \spacechar & \checkmark & \spacechar & \spacechar & \checkmark & \checkmark & \checkmark \\
  \bottomrule
\end{tabularx}
\caption{The matrix of misinformation}
\label{tab:matrix}
\end{threeparttable}

\subsection{The ecosystem}
\label{ssec:1-ecosystem}

\sidequote{What had gone wrong was the belief in this untiring and unending accumulation of hard facts as the foundation of history, the belief that facts speak for themselves and that we cannot have too many facts, a belief at that time so unquestioning that few historians then thought it necessary-and some still think it unnecessary today-to ask themselves the question: What is history?}{E.H. Carr}{}{What Is History?}\citeauthoryear{Wardle:2017b} expand on Wardle's original typology in what can be regarded as one of the most in-depth explorations on the misinformation landscape to date. In this work, they present a conceptual framework that offers a useful perspective for understanding the misinformation ecosystem. In contrast to other authors, they use the term \emph{information disorder} as a substitute for \emph{fake news}, to encapsulate \emph{mis-}, \emph{dis-}, and, what they call \emph{mal-information}—apt for conveying the mélange of problems faced in a post-truth world.

Simply put, disinformation involves intentionally creating or sharing false information to cause harm. In other words, it contains deliberately and verifiably falsified information. Mal-information is genuine information shared with deceptive intent. Lastly, akin to a rumour, misinformation is false information but not originally intended to cause harm. This should not be confused with a \emph{rumour}, which is `an unverified or unconfirmed statement or report circulating in a community.'\sidecitedefinition{Oxford English Dictionary}{OED:rumour} A rumour may later be verified as true or false, whereas disinformation is false from the onset.

Manifold, acceptable definitions of basic terms can be found in the literature of misinformation; their misdefinitions can also be encountered. Therefore, paying close attention to definitions of terms related to the problem is critical. Otherwise, it may compound the problem. For example, \citeauthoryear{Zubiaga:2018} observed that \citeauthoryear{Cai:2014} and \citeauthoryear{Liang:2015} incorrectly defined a rumour.\sidenote{Both define a rumour as false information, whereas the proper definition is as information whose veracity is not yet known.}

Wardle further corraled a fairly comprehensive glossary in which she defined common terms and acronyms associated with the misinformation disorder landscape.\sidecite{Wardle:2018} Attempts such as Wardle's, to clarify misinformation-related terms are crucial for aiding researchers and the general public in assimilating the scope of the problem of misinformation. Another such work is that of the media historian and theorist Caroline Jack, who created a lexicon for media content, aimed at educators, policymakers and others.\sidecite{Jack:2017}

\subsection{What is fake news?}
\label{ssec:fake-news}

Fake news essentially means disinformation. It arguably is the term most widely used to refer to multiple categories of information disorder. Although the term was once used in a corrective and progressive manner,\sidecite{Gelfert:2018} its positive connotation has since split into a duality—it is now used to refer to disinformation, and critique and deride mainstream media.\sidenote{\citeauthoryear{Wardle:2017b}, \citeauthoryear{Caplan:2018}} Furthermore, `fake news' is also used, ironically, to denounce or discredit factual information as misinformation. The phrase has recently become a tool for tactical subversion from truth and, especially in politics, for slander against dissenting opposition.

Documented uses of `fake news' in writing date back to the 1890s; however, other terms denotative of misinformation go as far back as the 16th century.\sidecite{MWD:2017} \citeauthoryear{Gelfert:2018} carried out an in-depth study of the etymology of fake news. The study lists examples of previous attempts at defining the phenomenon and why they are inadequate; it also gives historical examples of attempts to define fake news. The following definition from Gelfert is adopted in this thesis:

\begin{quote}
  \begin{Center}
  \emph{`Fake news is the deliberate presentation of (typically) false or misleading claims as news, where the claims are misleading by design.'}
  \end{Center}
\end{quote}

The term `fake news' may be unideal to refer to all kinds of misinformation. However, it is popular among the public and researchers of misinformation alike. Although `fake news' may be a convenient catch-all term, it does not accurately reflect the nuances and complexities of misinformation. Therefore, it is crucial to exercise caution when using this terminology and consider alternative descriptors that may be more appropriate for specific contexts or types of disinformation.

As it is now used to denote the entire spectrum of information disorder, `fake news' sometimes educes ambiguity. Understandably, most people will not be familiar with the minutia of a research area, no matter how relevant it is. Moreover, people may prefer simpler, more relatable terms for use in conversation. For these reasons, it may be permissible to call most kinds of misinformation fake news. However, the term is strictly inadequate and inaccurate. Misinformation need not even be news in the first place. It is essentially corrupted information. But if one generalises to say `fake information', this is also problematic, because it negates correct information that is mistakenly shared with a false context.

\newthought{In response, some} have proposed using the term `false news' to refer to disinformation instead.\sidenote{\citeauthoryear{Oremus:2017}, \citeauthoryear{Habgood-Coote:2018}} But what happens when those who use fake news in subversive ways also begin to use `false news' in the same manner? Quite often, the intent of an actor who shares problematic information cannot be promptly proven or inferred. It appears, at least in research, that `misinformation' is used as an umbrella term for information disorder. This is less obscure because although it does not strictly classify a piece of information, it still insinuates that the information is problematic.

In this thesis, `fake news', `false news' and `misinformation' are used interchangeably, in a broader sense to refer to the scope of information disorder. Moreover, `real', `legitimate' and `authentic' are used to refer to reliable and truthful news. The focus of this thesis is on finding an algorithmic solution to hindering the spread of fake news, and not its epistemology. The reader is referred to \citeauthoryear{Tandoc:2018}, \citeauthoryear{Torres:2018} and \citeauthoryear{Zannettou:2019} for further in-depth studies of the typology and epistemology of fake news.

\subsection{A Brief History of Fake News}
\label{ssec:1-history}
\sidequote{Since wit and fancy find easier entertainment in the world than dry truth and real knowledge, figurative speeches and allusion in language will hardly be admitted as an imperfection or abuse of it. I confess, in discourses where we seek rather pleasure and delight than information and improvement, such ornaments as are borrowed from them can scarce pass for faults.}{John Locke}{}{An Essay Concerning Human Understanding, Book III}While it is beyond the scope this thesis to expand on the chronology of fake news, some key events may serve to sum up its timelessness. This summary will centre on a few domains palpably affected by it: war, natural disasters, healthcare, and politics.

Fake news predates news itself, at least, news conveyed through newspapers. Dating back to the 17th century and originally called \emph{newsletters}, newspapers were simply printed or handwritten letters used to exchange tittle-tattle. This activity grew and transformed into the production and consumption of modern newspapers.\sidecite{Park:1923}

\newthought{Long before newsletters,} however, the disinformation campaign had been a tactic in use. One example of note was in the Roman Empire. Following the demise of Julius Ceaser, Octavian and Antony launched disinformation campaigns against each other—employing propaganda, through the media of poetry, rhetoric and newly minted coins—in a bid to become emperor. This led up to the Battle of Actium, in 31 BC, out of which Octavian emerged the victor.\sidecite{Kaminska:2017} Though not its ultimate determiner, propaganda played a crucial role in the war. Misinformation has since been a prime weapon in the arsenal of warring entities. Or for inciting conflicts in the first place, as in the case of the Spanish-American War.\sidecite{Soll:2016}

The media and speed of disseminating fake news have drastically advanced. At the time of writing, Russia was continuing with its invasion of Ukraine. From the onset, the Russian state used various disinformation narratives to justify the invasion.\sidenote{\citeauthoryear{EEAS:2022},\citeauthoryear{US:2022}} Its current model of propaganda is high-velocity and unremitting, high-volume and multichannel, and lacking in objective reality or consistency. This approach has been developing since the Soviet Cold War era—to Russia's invasion of Georgia in 2008—to its annexation of the Crimean peninsula in 2014—and it is, in all probability, now deployed in Russia's invasion of Ukraine.\sidecite{Paul:2016}

Clearly, then, misinformation has had an enduring influence on conflicts, but so has it on many other areas of life: another is natural disasters. During the 15th century the readership of news significantly expanded, thanks to the birth of the printing press. Fake news followed suit, expectedly.\sidecite{Soll:2016} After all, the original newsletters helped gossip to set sail. After an earthquake in Lisbon, in 1755, pamphlets containing fake news\sidenote{To be precise, this was a mixture of witnesses' accounts, false context and manipulated content. It brought forth a new genre of sensational news called \emph{relações de sucessos}.} were circulated around Portugal.\sidecite{Araujo:2006} Today, there are various ways to fact-check news and other information. By contrast, fact-checking was a rarity then. In want of scientific understanding, several natural events, including natural disasters, were mystically interpreted.

\newthought{The term `infodemic'} was coined by \citeauthoryear{Rothkopf:2003}. It described the surge of information, true and false, related to the 2003 SARS epidemic. Mindful to not understate the severity of SARS itself, \citeauthor{Rothkopf:2003} argued that the `information epidemic' that resulted from it added a new and more worrisome dimension to the disease. Future global events would affirm \citeauthor{Rothkopf:2003}'s ominous piece. In the wake of the Coronavirus disease 2019 (COVID-19) pandemic, people all over the world frantically sought information and many hastily acted upon unverified information. To worsen matters, advice—including from the World Health Organization, governments, and other trusted and reputable was not only updated frequently, but at times, inconsistent. Naturally, some were stirred to doubt, anxiety, and confusion. Meanwhile, a steady flux of misinformation gushed out through \acp{OSN} (also known as social media). This culminated in an infodemic. Its impacts included psychological issues, loss of public trust, loss of lives due to misinforming protective measures, and panic purchase.\sidecite{Pian:2021} In 2018, the Democratic Republic of Congo experienced multiple outbreaks of the Ebola virus. The adoption of preventive measures against it was hampered by misinformation and low institutional trust.\sidecite{Vinck:2019} Other disease outbreaks such as the Zika virus, Middle East Respiratory Syndrome, and H1N1 Influenza (swine flu) were all adversely affected by misinformation.\sidecite{Chowdhury:2021}

\newthought{Newspapers have historically} carried misinformation—and occasionally, disinformation. Modern newspapers became more mainstream by the 19th century, and through them, true and false news travelled faster and farther. The news became more sensational too. For instance, in 1835, the New York Sun published multiple false articles claiming that there were aliens on the moon. This was known as the `Great Moon Hoax'.\sidecite{Soll:2016} In the 1890s, Joseph Pulitzer and William Hearst, rival American news publishers, contended for a larger readership of their newspapers. Each sought to succeed by dubious practices—blatant reportage of rumours as facts. This practice was known as `yellow journalism.'\sidecite{UCSB:2022}

The dynamics of misinformation became more complex when news leapt from paper onto web pages. News became boundless, and so did misinformation. Meanwhile, sensationalism reigned on. By and by, news websites became interlaced with advertisements, and sometimes, \emph{shockvertising} (\emph{i.e.}, designed to shock and provoke).\sidecitedefinition{Oxford English Dictionary}{OED:shockvertising} And to increase advertisement revenue, some resorted to \emph{clickbait}—attention-grabbing headlines designed to cajole readers into clicking links. Clickbait has taken up residence on the internet. To sell advertisements, `drive traffic', `increase engagement', or simply mislead, many websites resort to clickbait. It often misleads and can be acutely harmful. Yet, it remains inescapable on the web. In fact, it is believed that misinformation—largely in the form of clickbait shared on \acp{OSN}—influenced the outcome of the 2016 U.S. presidential election.\sidecite{Allcott:2017}

Perhaps only coinciding with, rather than causing it, greater attention was being paid to misinformation, as the internet made strides. Or perhaps, misinformation simply grew too rapidly to be ignored. In 2005, the \ac{ADS} named \emph{truthiness} its word of the year.\sidecite{ADS:2006} The Merriam-Webster Dictionary did the same the following year.\sidecite{MWD:2022}
In 2016, the \ac{OED} named \emph{post-truth} its word of the year.\sidecite{OxfordLanguages:2016} The next year, the \ac{ADS} and the Collins Dictionary both announced \emph{fake news} as their word of year.\sidenote{\citeauthoryear{Wright:2017}, \citeauthoryear{ADS:2018}} In 2018, \emph{misinformation} was named \href{https://www.dictionary.com}{Dictionary.com}'s word of the year.\sidecite{Dictionary:2018}

\newthought{It is unlikely} that any medium for sharing information that is open to the general public will be immune to misinformation. To say nothing of sharing news. The minimal cost of creating accounts and posting, combined with economic and social incentives, particularly encourages bad actors.\sidecite{Shu:2017} One potential threat in the future could be the misuse of generative artificial intelligence. It is likely that deep fakes—in text, audio, image, and video forms—will become more sinister. At any rate, they are becoming more realistic.

While exacerbating misinformation, the internet, at the same time, may be the most effective tool for stifling it. Especially through the strategic use of \acp{OSN}. Inoculation or `prebunking' is one such strategy. This means pre-empting oncoming information with facts. According to \citeauthoryear{Pilditch:2022}, inoculating a critical mass of users in a network can inhibit the consolidation of falsehood.\sidenote{They found that inoculating subsets of users at different times is also effective.} Their experiments were carried out using \acp{ABM}. While their results are promising, it should be borne in mind that their setup, as well as \acp{ABM}, are simplifications of the real-world. The same limitation applies to several other proposed approaches for stopping misinformation, including \ac{ML}-based ones. Nonetheless, such research should be spurred on.

Via the internet, suspicious information can be scrutinised in near real-time. Likewise, facts corrective to them can be dispensed quickly. Indeed, on the internet, registers of facts abound and are at hand for swift withdrawal. But fake news is multiplicative. For regarding a single fact, countless false narratives can sprout up. Therefore, it is easier for lies to accrete than for truth to flow. Another strategy, nevertheless, is education: on how to spot and retard misinformation, and how to seek and interpret facts.

It would seem that society is in an endless battle with misinformation; that it may take one form or another, but can never be fully eradicated; and that it will always be one step ahead of the safeguards in place. This could be true as long as there remains insistence on velocity and volume rather than clarity and nuance, and on flimsy metrics as the measure of the effectiveness of communication. All these could come true as long as there remains insistence on velocity and volume rather than clarity and nuance, and on flimsy metrics as the measure of communication. Not every problem can be solved by a technological breakthrough, or simply more information, no matter how factual it is. Especially those problems entangled with people's identities, tightly held beliefs and opinions, and their daily lives and bread. It may be necessary to rethink the design of communication tools (both small and large scale), some of the incentives for these communications, and the online communities that foster them. Misinformation will like become an increasingly thorny issue in the future, and it is, therefore, crucial to think outside the box to find effective solutions.

\section{Fake News On Social Media}
\label{ssec:1-fnosn}

\vspace*{-\baselineskip}

Social media platforms provide a medium where the production and sharing of news is not limited to established news agencies, but also open to the general public.\sidecite{Campan:2018} News agencies used to be the main \emph{creators} and \emph{distributors} of news. Today, however, the general public is a lot more involved in that process.\sidenote{Advances in smartphone and web technologies, now allow events to be broadcasted by members of the public with great speed and quality.} In fact, so-called \emph{content creators} (\ie, people from various fields who create media content for consumption, primarily on the internet) are thriving, particularly in technology news. Furthermore, people of all age groups and from all parts of the world interact, share and exchange information on \acp{OSN}. This makes it a suitable medium for rapidly spreading misinformation. Satisfactory solutions to counteracting this challenge have not yet been found.

To sum up, misinformation on social media must be tackled. Given that this problem is multifaceted and dynamic, the ideal solution would equally be holistic and dynamic in its workings. Given its complexity, it must be approached pensively and with nuance. It is highly unlikely that the solution will be simple, if there is one at all—misinformation is a `wicked problem'.\sidenote{\citeauthoryear{Rittel:1973} formulated the idea of a `wicked problem' (in social policy) as one that is onerous or insoluble, characterised by 10 features, which \citeauthoryear{Conklin:2006} generalised to the following six: \begin{enumerate}
    \item It is understood after a solution is developed.
    \item It has no stopping rule.
    \item Its solutions are not right or wrong.
    \item It is novel and unique.
    \item Every solution is a `one shot operation'.
    \item It has no given alternative solutions.
\end{enumerate}}

\newthought{Whether in research} or deployment on the web, a multidisciplinary approach is ideally needed to combat misinformation. It has traditionally been combatted through manual fact-checking by experts. In addition to news agencies, other fact-checking organisations such as FactCheck\sidenote{\raggedright\url{https://www.factcheck.org}}, Snopes\sidenote{\raggedright\url{https://www.snopes.com}} and PolitiFact\sidenote{\raggedright\url{https://www.politifact.com}} employ such experts. Recently, however, computational techniques such as \ac{ML} have been used to detect misinformation.

This potentially allows for automated, real-time detection which can alert people whilst or after engaging with misinformation. Furthermore, it can help in identifying social media accounts that spread misinformation. A lot of research work has been done in this area, but there remain limitations which hinder their application in real-world scenarios. One such limitation is the need for large news datasets annotated by experts.

\section{Why Machine Learning and Online Social Networks?}
\label{ssec:1-whyml}

\subsection{Access and participation on OSNs}
\label{ssec:1-access}

News is ubiquitous on \acp{OSN} and people access news through them. According to a survey by the Pew Research Center in the United States, 53\% and 48\% of US adults got their news from \acp{OSN} in 2020 and 2021, respectively.\sidecite{Pew:2021} The United Kingdom's Office of Communications (Ofcom) stated in its 2021 report on nationwide news consumption, that about half of adults in the UK access news on social media.\sidecite{Ofcom:2021} This trend transcends the Anglosphere. The Reuters Institute for the Study of Journalism at the University of Oxford, which aims to understand global news consumption, has been publishing its \emph{Digital News Report} for the past decade. Its research focuses on countries with a high internet penetration and the 2021 report covered data from 46 countries across five continents. The report focused on the six largest \acp{OSN}—Facebook, YouTube, Twitter, Instagram, Snapchat, and TikTok—according to weekly use. In it, the Reuters Institute found that more than half of the Facebook and Twitter users surveyed encountered news on those platforms in the past week; for other networks, less than half of the users did.\sidecite{ReutersInstitute:2021} They also found that for many Facebook users, the encounter with news on the platform is incidental rather than intentional. In fact, some people report avoiding it altogether.

It should be expected that more people seek and find news on social media. After all, news sites and blogs share, and nudge people to share content on social media. Social media is apt for aggregating news from various sources, as well as for commentary and discussion. Furthermore, people themselves, now \emph{create} news online by directly posting onto their profiles. In other words, social media activity sometimes \emph{is} the news itself. Therefore, the creation of news is becoming more democratised and social media is continuously being reinforced as the global nucleus of news activity—from witnessing to disseminating, to assimilating. However, along with this new-found voice and power follow ramifications. Most inimically, noise and lies compete with signal and truth, for space and attention.

\newthought{Apart from reading} news, people are generally spending more time on social media. It is also used to interact with friends and strangers, engage in public discourse or dissent, and more recently, to shop and donate to charitable causes, directly. It is not an overstatement, then, to say that social media has accrued an enormous value—or cost, depending on how one sees it—for nearly everyone. Misinformation arguably spreads the fastest on \acp{OSN} amongst news media. Now, if people's lives and livelihoods continue to be intricately intertwined with social media—if people are to find ways of navigating, or escaping, the real-world through it; to stay in touch and make new friends; to form and maintain communities and identities; find self-expression; to share memes and commiserate with one another—then it is worth protecting. Especially when it influences real-world events and politics. One of the consequences—or benefits, as the case may be—of wallowing in social media feeds is that it gradually shapes one's worldview. The design and resulting dynamics of \acp{OSN} make their users susceptive of a myriad of biases—information, political, cognitive, \emph{etc.}\sidenote{\citeauthoryear{Menczer:2020}, \citeauthoryear{Barrett:2021}} Fake news detection is currently mostly done by human experts. This is very expensive and time-consuming given the deluge of misinformation that parades \acp{OSN} daily. This work contributes to lessening the cost and effort spent by experts.\sidenote{See \sectionref{ssec:1-labelling}.}

\subsection{Are OSNs doing enough to curb misinformation?}
\label{ssec:1-efforts}

At the ever-rising speed and scale of misinformation dissemination on social media, and considering that more and more people are reading news on them, the problem is proving to be insurmountable for human experts alone to deal with. The situation is critical, and the skills and resources needed for repair are limited. However, \ac{ML} algorithms can augment the effort of experts combatting the problem. An example of how this can be done is explained in the next subsection (\sectionref{ssec:1-labelling}). Beyond intercepting misinformation, algorithms, more generally—as can be seen in this thesis and some of the works cited in it—are extending the capacity for unravelling the tangle of misinformation. A collection of algorithms, therefore, can act both as tools and as catalysts, matching the speed and scale at which misinformation propagates on \acp{OSN} and its complexity.

\newthought{Whilst employing people} to spot problematic content including misinformation and false news ensures detection accuracy, this has been found to have detrimental effects on the moderators of social media content.\sidecite{Newton:2019} Firstly, repeated exposure to the kinds of disturbing media moderators scour out, can corrode a person's mental well-being. Besides that, reading false information repeatedly can lead one to believe it is true; this is a phenomenon called the \emph{illusory truth effect}.\sidecite{Pennycook:2021} Finally, in spite of their invaluable contributions, content moderators are rather stingily remunerated for their work.

In the case of Facebook, moderators are paid as low as \$1.50 and \$15 per hour, in Kenya and the United States, respectively. In both cases, these people are employed by contractors and not directly by Facebook. However, Facebook's own employees audit their work and periodically visit the contractors' offices for monitoring. Nonetheless, their pay is meagre and they are treated poorly, all in sharp contrast to the median salary of \$240,000 and numerous additional perks, which Facebook employees enjoy.\sidenote{\citeauthoryear{Newton:2019}, \citeauthoryear{Perrigo:2022}}\sidenote{This comparison does not mean to suggest that moderators should receive equal pay to other employees. (Although they definitely should be paid more and treated better.) Rather, it serves to elucidate that their role is regarded as subservient to those of others.} Content moderators have reported struggling with mental trauma and indeed, some have been diagnosed with traumatic stress disorders. This is supposedly triggered by the appalling content they review. However, they have also reported facing intimidation and overwhelming pressure from their managers at work.\sidenote{Ibid.} This compounds their work-related stresses rather than alleviating them. In 2019, a Facebook content moderator passed away, at work, at his desk. The management of the contracted company initially responded by dissuading their employees from discussing the tragedy, because they worried that it would dwindle productivity.\sidecite{Newton:2019b} These findings raise some serious questions about the earnestness of social media platforms in fighting misinformation.

Misinformation is a dynamic and convoluted problem. So much so that it seems misinformation will never be totally eradicated—but will always take one form or another—and can only be repeatedly extinguished. Such a volatile and amorphous nature demands supervision and intervention by experts. It is clear to see, then, the long-term significance of content moderation on \acp{OSN}, and the internet as a whole.

\newthought{It would be} unfair to social media companies if their efforts in combatting misinformation were not recognised. They have undertaken and funded numerous projects and initiatives, which demonstrate a sincere concern for the safety of their users. These also throw light on the multifaceted nature of the problem at issue.

Firstly, \acp{OSN} provide access to data for research purposes, through APIs or competitions. Research activities such as fake news detection using \ac{ML} will not be practical without datasets, though some researchers have expressed a demand for additional data, \emph{e.g.}, impression data.\sidecite{HKS:2020} In addition to data, \acp{OSN} platforms support researchers with grants. Therefore, notable contributions are made in support of research activities.

Secondly, \acp{OSN} are making it easier for people to flag or report posts they deem ill. Twitter, for instance, has taken this one step further through their Birdwatch pilot programme.\sidecite{Coleman:2021} Users (in the U.S., for the time being) can directly annotate tweets they believe to be misleading, thereby providing context for the flag. These notes are publicly viewable by anyone. Beyond simplistic binary labels, this will provide more insight to Twitter users and researchers alike, for understanding the roots of misinformation.

Thirdly, these companies have established coalitions and partnerships with academia, media, fact-checking and other organisations, to work together towards achieving shared goals for the public good. Notable examples of such consortia include Social Science One,\sidenote{\raggedright\url{https://socialscience.one}} the Content Authenticity Initiative,\sidenote{\raggedright\url{https://contentauthenticity.org}} and the Coalition for Content Provenance and Authenticity.\sidenote{\raggedright\url{https://c2pa.org}} An outstanding, individual example is the Google News Initiative,\sidenote{\raggedright\url{https://newsinitiative.withgoogle.com}} which boasts more than 7,000 partnerships and \$300 million in funding to various organisations in over 120 countries.

In addition, \acp{OSN} also:

\begin{itemize}
    \item build in-house tools for detecting misinformation; they also incorporate new tools and expertise through company acquisitions (\emph{e.g.}, Fabula AI being acquired by Twitter,\sidecite{Agrawal:2019} and Bloomsbury AI by Facebook\sidecite{Winick:2018})
    \item create robust, independent and transparent decision-making structures, which include external experts (\emph{e.g.}, the Oversight Board\sidenote{\raggedright\url{https://www.oversightboard.com}} established by Facebook in 2018, which oversees critical content moderation on Facebook and Instagram)
    \item try to adapt their policies to current affairs and adhere to government policies around the world
\end{itemize}

All that is mentioned here is not an exhaustive list of measures taken by social media platforms. But are they doing enough? While some of their efforts are commendable, there are areas where \acp{OSN} ought to improve.

\newthought{It is helpful} to constantly bear in mind that profit—primarily through advertising—is a top priority for social media companies. Notwithstanding the Google News Initiative's generous funding to various organisations, a noteworthy detail is that Google itself has a news product, Google News, which helps to drive user engagement with other Google products, such as search. Moreover, as of 2018 news accounted for 16-40\% of Google Search results, and content crawled and scraped from news publishers drew in an estimated \$4.7 billion according to the \citeauthoryear{NMA:2019}. Debate continues as to whether \acp{OSN} should reward publishers for their images and text which appear in search results, or if the publishers are better off for the additional web traffic. Publishers initially received nil from \acp{OSN} for their content, but this is no longer the case.\sidecite{Google:2021}

Are \acp{OSN} willing to come up with tougher policies, which may hinder misinformation at the expense of some profit? Misinformation is common in advertising. According to \citeauthoryear{Chiou:2018}, advertising makes a significant contribution to the spread of misinformation. To give some perspective, the U.S. Federal Trade Commission filed more than 150 instances of misinformation in adverts between 2015 and 2020; the settlements were as high as \$191 million.\sidecite{Fong:2021}

\newthought{All in all,} users have a role—perhaps the biggest role, individually and collectively—to play in curbing misinformation. After all, users—businesses and individuals—generate most of the content on social media. In fact, according to \citeauthoryear{Vosoughi:2018}, real human accounts \emph{not} bots, are mostly responsible for sharing misinformation on Twitter.


\subsection{Alleviating the strain of labelling}
\label{ssec:1-labelling}

Supervised \ac{ML} models for detecting fake news rely on labelled data. As such datasets are usually large, labelling them can be tedious. This process is expensive, exhausting and in some cases, detrimental to the well-being of those carrying out the task. These issues, as well as the low wages paid for labelling tasks, are discussed in the previous subsection. Further potential problems with labelling are that it does not scale, and it has an element of subjectivity.

Unsupervised \ac{ML} models, on the other hand, do not rely on labelled data. Therefore, it can help to alleviate some of these issues. It would be ideal to minimise the effort required for labelling data while maintaining accuracy. In that sense, therefore, this thesis explores unsupervised learning as an alternative to supervised learning. 

\subsection{Algorithms are versatile and catalytic}
\label{ssec:1-algo}

Will \ac{ML} algorithms someday be able to speedily and single-handedly spot every problematic content on \acp{OSN}? This is unlikely, for there will always be many borderline cases, and even humans sometimes disagree on how content should be classified. However, when the economic and psychological costs of human reviewing are considered, \ac{ML} can make significant contributions to curbing problems such as information disorder. Moreover, it has, by and large, successfully been used to tackle other issues such as nudity on \acp{OSN}.

The scale of \acp{OSN} make them fertile grounds for the rapid spread of false news, with billions of people actively using them. History shows that \acp{OSN} have a revolutionary power. For instance, social media played a critical role in the Arab Spring of 2011\sidecite{Brown:2012}, and more recently, in the 2016 U.S. Presidential Elections\sidecite{Allcott:2017}. Further, \acp{OSN} are environments from which new culture (\emph{e.g.}, memes) permeates into the real world, and they, therefore, influence the lives of individuals. As such, it is important to rid it of harmful actors and behaviours such as misinformation. Fortunately, the availability of datasets on false information in \acp{OSN} makes research on combatting the issue with algorithms feasible.

\section{Project aim}
\label{ssec:1-aim}

Existing implementations of semi-supervised and unsupervised \ac{ML} are fewer and less varied than those of supervised learning. Work has been done aplenty in the supervised learning space, and good progress has been made. However, there are limitations which restrict its applicability, such as the need for labelled data.

There is also a need for new text representations that are robust for detecting misinformation. For example, it is common to use text features based on writing style. However, they may not be robust enough to identify false news written in a similar style to real news.

\newthought{The aim of} this research is to develop a novel approach for generating text representations from short and long-form texts. Furthermore, it aims to demonstrate the efficacy of such representations for misinformation detection, using unsupervised and supervised \ac{ML}.

First, in \autoref{ch:related-work}, this thesis explores existing ways of utilising text features for misinformation detection. Second, in \autoref{ch:word-embeddings}, experiments exploring how to harness text representations to detect fake news are presented. \autoref{ch:thematic-coherence} introduces the concept of \emph{thematic coherence}, based on analyses of topic features in news pieces. Finally, \autoref{ch:clustering-and-classification} shows results for detecting misinformation with topic representations using clustering and classification.

\subsection{Contributions}
\label{ssec:1-contributions}

Given their influence and harmfulness, a lot of research work has been done to address the elements of information disorder. This research focuses on mis- and disinformation. It mainly contributes to the existing body of work on misinformation detection using \ac{NLP} and \ac{ML}.

Firstly, an exploration of features for misinformation detection is carried out. A novel feature extraction approach, involving topic modelling, for classifying and clustering news articles is presented. Topic-based features are advantageous in situations where labelled data is difficult to acquire, available in a small quantity or non-existent. Additionally, topic features may be more robust when faced with machine-generated fake news, unlike the commonly used stylometric ones.\sidecite{Schuster:2020}

Secondly, supervised and unsupervised \ac{ML} methods are applied to detect misinformation, in multiple cross-domain datasets.

Lastly, the findings of this research may be applicable in other problem areas on the spectrum of information disorder in news text, \emph{e.g.} hate speech detection. Also, this research more broadly contributes to the field of \ac{NLP}. The experiments carried out and their results may be informative to other researchers in the field. The code for all the experiments presented in this thesis is available at \href{https://github.com/m-arti/mphil}{\url{https://github.com/m-arti/mphil}}.

% end of chapter
